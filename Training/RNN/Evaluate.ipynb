{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMDiap30C1iEPUSNYnYNytS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","import re\n","import numpy as np\n","import time\n","\n","from torch.utils.data import Dataset, DataLoader, TensorDataset\n","\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import time\n","from collections import deque\n","\n","from sklearn.model_selection import GridSearchCV\n","import random\n"],"metadata":{"id":"8nVe6tMagDc8","executionInfo":{"status":"ok","timestamp":1716669934899,"user_tz":-120,"elapsed":5762,"user":{"displayName":"Emilia Sj√∂gren","userId":"10339343878085003295"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["\n","class DeepNetwork(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim=100, hidden_size=256, num_layers=2, drop_out=0.0):\n","        super(DeepNetwork, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        self.rnn = nn.GRU(embedding_dim, hidden_size, num_layers=num_layers, batch_first=True, dropout=drop_out)\n","        self.final = nn.Linear(hidden_size, vocab_size)\n","\n","    def forward(self, t, hidden):\n","        embeddings = self.embedding(t)\n","        out, hidden = self.rnn(embeddings, hidden)\n","        out = self.final(out[:, -1, :])\n","        return out, hidden\n","\n"],"metadata":{"id":"Xs3IuB87gBzp"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"33skH25Vf7RQ"},"outputs":[],"source":["class Evaluate:\n","    def __init__(self, file_path, device='cpu'):\n","        self.device = device\n","        self.load_model(file_path)\n","\n","    def load_model(self, file_path):\n","        checkpoint = torch.load(file_path, map_location=self.device)\n","\n","        # Reconstruct the text processor\n","        self._w2i = checkpoint['w2i']\n","        self._i2w = checkpoint['i2w']\n","\n","        # Retrieve model parameters\n","        embedding_dim = checkpoint['embedding_dim']\n","        hidden_size = checkpoint['hidden_size']\n","        num_layers = checkpoint['num_layers']\n","        vocab_size = checkpoint['vocab_size']\n","        drop_out = checkpoint['drop_out']\n","\n","        # Reconstruct the model with parameters loaded from the checkpoint\n","        self.model = DeepNetwork(vocab_size, embedding_dim, hidden_size, num_layers=num_layers).to(self.device)\n","        self.model.load_state_dict(checkpoint['model_state_dict'])\n","        self.model.eval()\n","\n","        # Load losses and accuracies\n","        self.losses = checkpoint['losses']\n","        self.accuracies = checkpoint['accuracies']\n","        self.accuracies_words = checkpoint['accuracies_words']\n","        self.epoch_acc = checkpoint['epoch_acc']\n","\n","        self.sequence_length = checkpoint['sequence_length']\n","        self.num_layers = checkpoint['num_layers']\n","        self.hidden_size = checkpoint['hidden_size']\n","        self.eval_text = checkpoint['eval_text']\n","\n","        print(f\"Model loaded from {file_path}\")\n","\n","    def generate_text(self, seed_text, next_words=50):\n","        self.model.eval()\n","        words = seed_text.lower().split()\n","        hidden = None\n","\n","        for _ in range(next_words):\n","            input_indices = [self._w2i[word] if word in self._w2i else 0 for word in words[-self.sequence_length:]]\n","            input_tensor = torch.LongTensor([input_indices]).to(self.device)\n","\n","            with torch.no_grad():\n","                output = self.model(input_tensor)\n","\n","            output = output.squeeze(0)[-1]\n","            probabilities = F.softmax(output, dim=0).cpu().numpy()\n","\n","            top_indices = np.argsort(probabilities)[-5:][::-1]\n","            top_words = [self._i2w[idx] for idx in top_indices]\n","            top_probs = probabilities[top_indices]\n","\n","            predicted_index = np.random.choice(top_indices, p=top_probs/top_probs.sum())\n","            predicted_word = self._i2w[predicted_index]\n","            words.append(predicted_word)\n","\n","        return ' '.join(words)\n","\n","    def _generate_words(self, input_indices, neighbours, hidden):\n","        input_tensor = torch.LongTensor([input_indices]).to(self.device)\n","        with torch.no_grad():\n","            output, hidden = self.model(input_tensor, hidden)\n","\n","        output = output.squeeze(0)\n","\n","        probabilities = F.softmax(output, dim=0).cpu().numpy()\n","\n","        top_indices = np.argsort(probabilities)[-neighbours:][::-1]\n","        top_words = [self._i2w[idx] for idx in top_indices]\n","        top_probs = probabilities[top_indices]\n","\n","        return top_indices, top_words, hidden\n","\n","\n","    def evaluate_text(self, neighbours=5):\n","        start = self.eval_text[0]\n","        saved_keystrokes = 0\n","        total_keystrokes = 0\n","\n","        found_words = 0\n","        total_words = 0\n","\n","        input_indices = deque([start], maxlen=self.sequence_length-1)\n","\n","        hidden = torch.zeros(self.num_layers, 1, self.hidden_size).to(self.device)  # Ensure correct device\n","        for index in self.eval_text[1:]:\n","            top_indices, top_words, hidden = self._generate_words(input_indices, neighbours, hidden)\n","\n","            fw, sk = self.evaluate_options(self._i2w[index], top_words)\n","\n","            saved_keystrokes += sk\n","            found_words += fw\n","\n","            total_words += 1\n","            total_keystrokes += len(self._i2w[index])  # Adjust index to get the actual item\n","            input_indices.append(index)  # Adjust index to get the actual item\n","\n","        print(f'Saved keystroke percentage: {100*saved_keystrokes/total_keystrokes:.2f}%')\n","        print(f'Found words percentage: {100*found_words/total_words:.2f}%')\n","        return saved_keystrokes/total_keystrokes, found_words/total_words\n","\n","\n","    def evaluate_options(self, target_word, options, nr_of_suggestions=5):\n","        \"\"\"Target word is the next word, options is a list of the k most probable words according to the model\n","        Outputs found_word which is 1 if the target_word is in options else 0\n","        Outputs saved_keystrokes which is the amount of saved keystrokes, 0 if target_word not in options\"\"\"\n","        if target_word in options:\n","            if target_word in options[:nr_of_suggestions]:\n","                found_word = 1\n","                saved_keystrokes = len(target_word)\n","                return found_word, saved_keystrokes\n","            for len_of_word in range(len(target_word)+1):\n","                options = [word for word in options if word[:len_of_word] == target_word[:len_of_word]]\n","                if target_word in options[:nr_of_suggestions]:\n","                    found_word = 1\n","                    saved_keystrokes = len(target_word) - len_of_word\n","                    return found_word, saved_keystrokes\n","            return (0, 0)\n","\n","        else:\n","            found_word = 0\n","            saved_keystrokes = 0\n","            return found_word, saved_keystrokes\n","\n","\n"]},{"cell_type":"code","source":["evale = Evaluate('model.pth')"],"metadata":{"id":"27qqsKSpgITD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["evale.evaluate_text()"],"metadata":{"id":"j8lLXraugJpz"},"execution_count":null,"outputs":[]}]}